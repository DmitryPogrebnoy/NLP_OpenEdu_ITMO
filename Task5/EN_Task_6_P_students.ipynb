{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "EN_Task_6_P_students.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQp47ajD2Ga4"
   },
   "source": [
    "# Basics of word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_Pat15ls9N8"
   },
   "source": [
    "## Download the model\n",
    "Download <code>google-news-vectors</code> model. Open it using the <code>gensim</code> library."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nd-xNyAGy1tT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613986101353,
     "user_tz": -180,
     "elapsed": 91923,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "f146551b-280f-49da-ac06-1a2c7cc7b7bc"
   },
   "source": [
    "! pip install -U gensim\n",
    "! wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "! gunzip GoogleNews-vectors-negative300.bin.gz\n",
    "! pip install SciPy==1.5.4"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/Dmitry.Pogrebnoy/Desktop/NLP_OpenEdu_ITMO_Course/venv/lib/python3.9/site-packages (4.1.2)\r\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/Dmitry.Pogrebnoy/Desktop/NLP_OpenEdu_ITMO_Course/venv/lib/python3.9/site-packages (from gensim) (1.5.4)\r\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/Dmitry.Pogrebnoy/Desktop/NLP_OpenEdu_ITMO_Course/venv/lib/python3.9/site-packages (from gensim) (1.22.3)\r\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/Dmitry.Pogrebnoy/Desktop/NLP_OpenEdu_ITMO_Course/venv/lib/python3.9/site-packages (from gensim) (5.2.1)\r\n",
      "--2022-03-16 09:39:52--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\r\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.113.93\r\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.113.93|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1647046227 (1.5G) [application/x-gzip]\r\n",
      "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\r\n",
      "\r\n",
      ".bin.gz               3%[                    ]  61.96M   875KB/s    eta 43m 53s^C\r\n",
      "gzip: GoogleNews-vectors-negative300.bin already exists; do you wish to overwrite (y or n)? ^C\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-4xfcycMynhZ"
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "w = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", \n",
    "                                      binary=True)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6JtQjaORfzA"
   },
   "source": [
    "The structure is entitled <code>KeyedVectors</code> and in essence it is an embedding between the keys and the vectors. Each vector is identified by its search key, this is most often a short string token,  therefore, it's normally a correspondance between\n",
    "\n",
    "<center><code>{str => 1D numpy array}</code></center><br/>\n",
    "\n",
    "\n",
    "\n",
    "For example, let's dispaly first 10 coordinates of a vector, corresponding to the word <code>sunrise</code>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ol9DuE6VRfzH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613987392235,
     "user_tz": -180,
     "elapsed": 629,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "11193923-cab0-4cbe-84bb-0fb8b957209b"
   },
   "source": [
    "print(gensim.__version__)\n",
    "print(\"Vector size: \", w[\"sunrise\"].shape)\n",
    "print(\"The first 10 coordinates of a vector: \\n\", w[\"sunrise\"][:10])"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.2\n",
      "Vector size:  (300,)\n",
      "The first 10 coordinates of a vector: \n",
      " [-0.22558594 -0.03540039 -0.21679688  0.03613281 -0.2265625  -0.09814453\n",
      "  0.109375   -0.34570312  0.18652344  0.01806641]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rv9Rqvq2af8"
   },
   "source": [
    "## Task 1. Similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mns8gpJFRfzd"
   },
   "source": [
    "Build vectors for the words <code>London</code>, <code>England</code>, <code>Moscow</code>. Compute the cosine distance between the words <code>London</code> and <code>England</code> and between the words <code>Moscow</code> and <code>England</code>. In which pair the words are more similar to each other? Hint: to compute cosine distance use the <code>distance()</code> method. The correct answer is presented in the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5600714385509491"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_vec = w[\"London\"]\n",
    "england_vec = w[\"England\"]\n",
    "moscow_vec = w[\"Moscow\"]\n",
    "\n",
    "w.distance(\"London\", \"England\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8476868271827698"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.distance(\"Moscow\", \"England\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9IrMkVi3Crm",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613987429028,
     "user_tz": -180,
     "elapsed": 591,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "f1fb13c1-73ce-4a52-b2a2-6393f1fd11c8"
   },
   "source": [
    "#enter your code here"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5793381929397583"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.distance(\"professor\", \"student\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLXEcSxt3DG4"
   },
   "source": [
    "## Task 2. Analogies.\n",
    "Using the most_similar method solve the analogy\n",
    "```London : England = Moscow : X```\n",
    "\n",
    "The correct answer is in the outputs.\n",
    "\n",
    "(Hint: use the following arguments: positive and negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[('Russia', 0.6502718329429626),\n ('Ukraine', 0.5879061818122864),\n ('Belarus', 0.5666376352310181),\n ('Azerbaijan', 0.5418694615364075),\n ('Armenia', 0.5300518870353699),\n ('Poland', 0.5253247618675232),\n ('coach_Georgy_Yartsev', 0.5220180749893188),\n ('Russian', 0.5214669108390808),\n ('Croatia', 0.5166040658950806),\n ('Moldova', 0.5125792026519775)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M - L + E = X\n",
    "w.most_similar([\"Moscow\", \"England\"], [\"London\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4Pqub5c3DV8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613987464034,
     "user_tz": -180,
     "elapsed": 15164,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "1e56d7aa-c6ce-4492-9ec8-d9c89fff2216"
   },
   "source": [
    "#enter your code here"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFzneqrn3Djq"
   },
   "source": [
    "## Taks 3. Similarity: find the odd-one-out word. \n",
    "Using the <code>doesnt_match</code> method, find the odd-one-out word in the string <code>breakfast cereal dinner lunch</code>.\n",
    "\n",
    "The correct answer is in the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'cereal'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.doesnt_match([\"breakfast\", \"cereal\", \"dinner\", \"lunch\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'wood'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.doesnt_match([\"professor\", \"student\", \"smart\", \"wood\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "493uH-D33DxJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613987507511,
     "user_tz": -180,
     "elapsed": 561,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "f42062e1-7a6c-46f1-956a-79992d348ea5"
   },
   "source": [
    "#enter your code here"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BT-Zl3YaRf0X"
   },
   "source": [
    "## Task 4. Sentence vector representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dm_SiyjU3D9G"
   },
   "source": [
    "\n",
    "A sentence is given: <code>the quick brown fox jumps over the lazy dog</code>. You need to represent this sentence as a vector. Therefore, build the vector representation for each word in the model, and then average the vectors component-wise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 9.05558243e-02,  5.43416329e-02, -6.71386719e-02,  1.09686956e-01,\n       -1.06065534e-02, -1.21066622e-01,  4.63748500e-02, -5.35685234e-02,\n        7.00683594e-02,  9.72764790e-02,  2.70589199e-02, -1.16495766e-01,\n        3.48307304e-02, -2.13351771e-02, -8.32519531e-02, -2.97851562e-02,\n       -3.11482754e-02,  1.02077909e-01, -7.70467147e-02, -1.05170354e-01,\n       -8.54492188e-04,  6.69555664e-02,  1.97482631e-02,  7.00336043e-03,\n        1.32700605e-02,  2.12593079e-02, -1.07652456e-01,  1.05970591e-01,\n        1.06550425e-01,  4.36740462e-03, -5.31684011e-02,  6.63248673e-02,\n        3.62277552e-02, -6.70505092e-02, -2.00195312e-02, -1.75272617e-02,\n       -2.21082903e-02,  6.37478312e-04,  9.91753489e-02,  1.46647140e-01,\n        9.37500000e-02, -1.67263448e-01,  1.36345759e-01, -1.23155378e-02,\n        5.61930351e-02, -6.90680593e-02, -5.95092773e-03, -5.62099889e-02,\n        8.73616561e-02,  7.48155415e-02, -3.18332240e-02,  7.09228516e-02,\n        7.61583149e-02,  4.37944196e-02,  6.64605014e-03,  8.74769390e-02,\n        1.05658639e-02, -9.99755859e-02,  6.37817383e-02, -3.54546458e-02,\n       -1.48179792e-02,  9.35058594e-02, -1.15152992e-01, -1.32080078e-01,\n        3.51630300e-02, -4.13682722e-02,  4.92587611e-02, -2.36409511e-02,\n       -8.00442174e-02,  3.93541120e-02,  1.24647349e-01,  3.15483958e-02,\n        6.87662745e-03, -2.08875872e-02, -1.03444420e-01,  1.89141165e-02,\n        4.39724401e-02,  6.63113073e-02, -2.57703988e-03,  9.86735001e-02,\n        1.63981114e-02, -4.85026054e-02,  7.04277903e-02, -6.75184429e-02,\n       -1.07591413e-02, -6.74641952e-02, -8.34825337e-02,  1.22205950e-02,\n        7.78164342e-02, -8.07427317e-02, -6.07367605e-02,  1.02715388e-01,\n       -1.53143987e-01, -1.04654945e-01, -3.21180560e-02, -4.63867188e-02,\n        1.15627712e-02, -8.09563498e-05, -3.96728516e-03, -8.68733693e-03,\n       -4.24647853e-02, -9.64355469e-02,  1.11463755e-01, -8.44828319e-03,\n        2.84288190e-02, -8.08919296e-02,  4.95062917e-02, -6.31917343e-02,\n        4.24397774e-02, -1.02764979e-01,  4.36740462e-03, -1.08371312e-02,\n        1.71305332e-02,  5.84920235e-02,  5.80240898e-02, -2.32747402e-02,\n        2.35222708e-02, -4.96961810e-02, -3.28776054e-02,  5.96245676e-02,\n       -1.53971359e-01, -2.04806849e-02, -9.47265625e-02, -3.73670785e-03,\n       -1.73068568e-02,  3.02225742e-02, -7.96847865e-02, -2.02365443e-02,\n        4.63595912e-02, -1.25596784e-02, -1.31849498e-01,  1.52994795e-02,\n       -1.26288518e-01,  2.78049037e-02, -5.92380092e-02, -2.09621862e-02,\n        6.83339462e-02, -1.35498047e-02,  8.64613876e-02,  1.77246094e-01,\n        5.36973737e-02, -5.43484166e-02, -4.06358503e-02,  1.44178607e-02,\n        8.62757396e-03,  7.26725236e-02, -9.62727889e-02,  8.93063005e-03,\n        1.97211374e-02, -2.58924700e-02,  1.55768499e-01,  8.51779524e-03,\n       -1.26627609e-01,  5.96245676e-02, -1.30316839e-01,  2.98428014e-02,\n        9.70458984e-03, -3.74060720e-02, -1.18164062e-01,  4.31586355e-02,\n       -5.90277761e-02,  5.33311628e-02,  9.66661274e-02, -7.50596821e-02,\n       -4.63460274e-02, -1.79485753e-02,  1.25123128e-01, -3.55902761e-02,\n        6.63248673e-02, -5.78613281e-02, -1.02945961e-01, -2.89984811e-02,\n       -2.11859811e-02,  3.08566615e-02, -5.99110909e-02,  8.70429166e-03,\n        6.41140416e-02, -9.98636857e-02, -4.70784493e-02,  9.14577916e-02,\n       -8.05799663e-02, -9.98738632e-02, -9.55132395e-02,  3.78417969e-03,\n       -5.48807764e-03, -1.23765729e-02,  5.44704869e-02,  5.05540632e-02,\n        6.05875663e-02,  4.98860665e-02,  5.03743477e-02, -8.46218541e-02,\n       -1.17119681e-02,  6.20456263e-02, -1.11219622e-02,  9.75341797e-02,\n       -8.01425502e-02, -7.68534318e-02, -8.83941650e-02,  1.99652780e-02,\n        5.29785156e-02, -2.84016933e-02, -6.77908510e-02, -3.85606550e-02,\n        1.70762800e-02,  2.40614153e-02,  1.60047738e-03,  7.26996548e-03,\n        2.10927334e-02,  6.40190952e-03, -1.26199082e-01,  1.87717006e-02,\n       -7.49172643e-02,  1.99584961e-02, -5.17578125e-02,  5.17272949e-02,\n        6.41716868e-02, -1.07693143e-01, -1.44110784e-01, -3.21112722e-02,\n        1.05794275e-03,  4.41894531e-02, -4.15649414e-02, -7.63990581e-02,\n        4.42301445e-02, -6.53754324e-02,  1.59261063e-01, -5.17103411e-02,\n        9.48689803e-02, -4.27449532e-02,  1.12365723e-01, -5.94075508e-02,\n        7.78537318e-02,  3.86394933e-02, -3.88573557e-02,  3.03276908e-02,\n        1.66015625e-01, -6.22151680e-02,  1.55504018e-01,  7.97729492e-02,\n        1.56229660e-01, -4.26974818e-02, -4.65223519e-03, -1.15963832e-01,\n        1.34874135e-01,  4.17751726e-03,  1.79850254e-02,  3.67838554e-02,\n        3.60005684e-02, -4.16937917e-02, -4.71310094e-02,  1.00708008e-02,\n        1.92057285e-02,  1.07828774e-01,  2.06027552e-02, -2.23185215e-02,\n       -4.58546728e-02,  1.12948949e-02, -1.08778208e-01,  1.68728307e-02,\n       -5.11338981e-03,  6.57755509e-02, -8.25466588e-02, -1.79578997e-02,\n        7.24555105e-02,  9.35872365e-03, -7.86471888e-02, -1.54079860e-02,\n       -9.13357213e-02,  4.18904610e-02,  1.88530814e-02,  1.49882004e-01,\n       -1.98025182e-02,  4.34570312e-02,  7.97797292e-02, -6.73149973e-02,\n       -3.72564532e-02, -5.94075508e-02,  2.20913365e-02,  1.26836985e-01,\n        1.06852211e-01,  2.54024938e-02,  6.39105886e-02,  1.50994197e-01,\n       -1.76323787e-03, -4.34027761e-02, -5.85666224e-02, -4.00119368e-03,\n       -2.56347656e-03, -3.20773665e-03, -4.59730364e-02,  1.64659284e-02,\n       -1.09002009e-01,  9.79953334e-02, -5.96788190e-02, -7.86539689e-02,\n        1.88547764e-02,  5.78782819e-02, -6.62163645e-02,  4.01746966e-02],\n      dtype=float32)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vectors = [w[\"the\"], w[\"quick\"], w[\"brown\"], w[\"fox\"], w[\"jumps\"], w[\"over\"], w[\"the\"], w[\"lazy\"], w[\"dog\"]]\n",
    "mean_vector_1 = np.mean(vectors, axis=0)\n",
    "mean_vector_1 = mean_vector_1.transpose()\n",
    "mean_vector_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FbM9gOT3Ofg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613987575947,
     "user_tz": -180,
     "elapsed": 648,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "93137b80-ace9-4c69-c411-b1d51c28d3c9"
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "#enter your code here"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1.74804688e-01,  5.86751290e-02,  5.55013008e-02,  5.99772148e-02,\n       -1.08093262e-01,  2.47701001e-03,  2.78828945e-02, -8.40148926e-02,\n        9.70636979e-02,  3.42814135e-03,  4.46777344e-02, -7.85318986e-02,\n       -1.08688988e-01,  2.02311203e-01, -2.14192703e-01,  1.14013672e-01,\n        5.37109375e-02,  2.02209473e-01, -2.84830737e-03, -5.38330078e-02,\n        2.13623047e-02,  6.97224960e-02,  1.08978271e-01,  7.29166642e-02,\n        1.26881912e-01,  7.93457031e-02, -5.19612618e-02,  6.87255859e-02,\n        4.23990898e-02, -8.61409530e-02, -4.06901054e-02,  6.40055314e-02,\n       -7.80944824e-02,  7.97526073e-03,  3.03344727e-02, -5.61523438e-02,\n        3.93981934e-02, -2.84016933e-02,  3.33461761e-02,  3.51969409e-03,\n        1.14908852e-01, -1.01684570e-01,  1.85282394e-01, -9.69441757e-02,\n        9.35872365e-03, -7.89591447e-02, -1.21515907e-01,  8.76057968e-02,\n        7.56835938e-03,  8.84602889e-02, -1.29699707e-02,  6.68004379e-02,\n        3.09143066e-02, -1.14789329e-01, -1.49332685e-02,  5.40771484e-02,\n       -2.54720058e-02, -1.24084473e-01,  7.78198242e-02, -6.99056014e-02,\n       -8.83992482e-03,  1.10453285e-01, -3.55962105e-02, -1.57623291e-02,\n       -6.21007271e-02, -3.85335274e-02, -4.91129570e-02,  7.36490861e-02,\n       -1.21907555e-01,  6.58162460e-02,  9.83072892e-02,  2.64485683e-02,\n        4.87976074e-02,  6.89519271e-02, -1.27380371e-01, -4.58564758e-02,\n        2.57161465e-02,  1.44226074e-01,  1.44653320e-02,  6.05672188e-02,\n       -3.40118408e-02, -8.52375031e-02, -2.29492188e-02, -2.75878906e-02,\n       -1.57877598e-02,  8.25805664e-02, -5.17578125e-02,  6.58162450e-03,\n        2.46988926e-02,  8.78855363e-02,  7.98034668e-02,  9.39331055e-02,\n       -6.75455714e-03, -8.28908309e-02, -2.76896153e-02, -1.13586426e-01,\n        1.83105469e-04,  6.73828125e-02,  6.78507462e-02, -3.80452462e-02,\n       -8.50423202e-02, -3.52376290e-02,  1.35904951e-02, -1.33870440e-02,\n        1.31785078e-02, -4.22566719e-02,  8.35571289e-02,  3.26334648e-02,\n        1.06038414e-01, -3.64379883e-02, -1.41398115e-02,  6.98930398e-02,\n        8.30790177e-02, -2.41292324e-02,  4.63663749e-02, -1.64591465e-02,\n        3.97440605e-02, -1.14298500e-01,  7.62557983e-02,  1.04085289e-01,\n       -3.66414376e-02,  2.61637364e-02, -7.71077499e-02, -1.08722849e-02,\n       -2.87272129e-02, -1.12759270e-01, -4.24397774e-02, -8.64410400e-03,\n        9.75748673e-02, -8.98437500e-02, -8.12174454e-02, -6.06282540e-02,\n        7.32421875e-03, -2.50447597e-02, -4.37011719e-02, -3.05074062e-02,\n        1.98567715e-02,  8.60290527e-02,  1.83105469e-02,  1.09822594e-01,\n        2.40478516e-02, -6.19913749e-02,  1.00097656e-02, -6.70572892e-02,\n       -1.09252930e-02,  1.46850586e-01, -1.10026039e-01, -1.42435715e-01,\n        4.82991524e-02, -4.22973633e-02, -1.03434242e-01,  4.87467460e-02,\n       -4.77701835e-02,  5.10253906e-02, -2.64485683e-02,  1.41805010e-02,\n       -7.56429061e-02, -3.85589600e-02, -4.82457466e-02,  1.38651533e-02,\n       -5.14119454e-02,  5.42805977e-02,  1.09741211e-01,  5.74747741e-04,\n        1.42415368e-03, -1.70450851e-01, -9.72493459e-03, -8.74226913e-02,\n       -1.04980469e-02, -1.18408203e-02, -7.26140365e-02, -1.29374191e-01,\n       -6.60400391e-02, -6.29475936e-02,  3.45865898e-02, -9.96907591e-04,\n        5.89548759e-02, -4.62239571e-02,  5.55623360e-02,  1.54622393e-02,\n       -1.95719395e-02, -7.44628906e-02, -8.57747421e-02,  1.55436201e-02,\n       -4.05680351e-02, -1.30289719e-01, -5.44128418e-02,  6.16861992e-02,\n        9.23665389e-02,  1.25528976e-01,  1.95109043e-02,  1.05061851e-01,\n       -6.92749023e-03,  5.91634102e-02, -8.04646835e-02,  9.85717773e-02,\n       -5.17985038e-02, -1.97550450e-02, -2.43733730e-02, -1.26464844e-01,\n        1.10066729e-02, -4.45556641e-03,  6.01399727e-02, -1.37532549e-02,\n       -3.88183594e-02, -4.65443917e-02, -1.01928711e-01, -1.45467126e-03,\n       -8.65478516e-02,  2.82541905e-02, -3.45458984e-02, -3.49934888e-03,\n        5.39042167e-02, -3.56038399e-02, -7.68941268e-02,  2.84220371e-02,\n        9.32210311e-02, -3.80045585e-02, -1.54317215e-01,  3.51130180e-02,\n        4.86380272e-02, -4.10156250e-02, -2.97444668e-02,  2.72623692e-02,\n        1.27248123e-01, -5.57454415e-02,  4.16666679e-02,  4.59798193e-03,\n       -4.97080497e-02, -9.24479142e-02,  1.75048828e-01, -4.04663086e-02,\n       -3.82588692e-02,  3.37073021e-02,  6.81559220e-02,  1.12304688e-02,\n       -5.45043945e-02, -8.02205428e-02, -2.23185215e-02,  4.18701172e-02,\n        4.01674919e-02, -1.59505215e-02, -2.02331543e-02, -3.26843262e-02,\n        1.21561689e-02,  2.26847325e-02,  1.10666908e-01,  1.98974609e-02,\n        6.59993514e-02,  5.82682304e-02,  3.03141270e-02, -8.15429688e-02,\n        7.77587891e-02,  9.91210938e-02,  3.59293632e-02,  1.73950195e-02,\n        1.61132812e-02,  8.33740234e-02, -6.12386055e-02,  1.11897783e-02,\n        7.51241073e-02, -8.97979736e-03, -6.41276017e-02,  7.91219100e-02,\n        7.13704452e-02,  1.40869141e-01, -1.63187668e-01,  2.05078125e-02,\n       -1.84860229e-02, -8.11971053e-02,  6.45243302e-02,  1.04695641e-01,\n        6.87255859e-02,  3.24605294e-02,  7.03938827e-02, -1.94905605e-02,\n       -9.35058594e-02, -1.31998703e-01,  1.63981114e-02, -2.89916992e-02,\n        6.70101270e-02, -7.51546249e-02, -2.51566563e-02,  4.91383858e-02,\n        3.52376290e-02,  4.50770073e-02, -4.38232422e-02,  6.74235001e-02,\n        1.49658203e-01,  1.79545078e-02, -3.84521484e-02,  9.79359969e-02,\n       -7.85115585e-02, -8.32112655e-02, -1.05794275e-03, -1.68863926e-02,\n        7.26725236e-02, -1.19649254e-01,  5.82682304e-02, -7.22173080e-02],\n      dtype=float32)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = [w[\"fool\"], w[\"his\"], w[\"money\"], w[\"are\"], w[\"soon\"], w[\"parted\"]]\n",
    "mean_vector_1 = np.mean(vectors, axis=0)\n",
    "mean_vector_1 = mean_vector_1\n",
    "mean_vector_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.00343541,  0.05318778,  0.03160749,  0.05688477, -0.07467216,\n       -0.0396031 , -0.04630825, -0.10288783,  0.04419817,  0.11659459,\n        0.05133929, -0.05517578,  0.0577319 ,  0.04078892,  0.0151825 ,\n        0.09943063,  0.0382952 ,  0.04654367,  0.00495257, -0.07195173,\n       -0.13546316,  0.09960938, -0.03876768,  0.03527396,  0.0859375 ,\n        0.00854492, -0.09682246,  0.03314209,  0.06549944, -0.020595  ,\n       -0.02453613,  0.0105678 , -0.07864816,  0.027274  , -0.10117885,\n       -0.01447405, -0.01053292, -0.03382656, -0.01391602,  0.01940046,\n       -0.02103097, -0.02934919,  0.06485421,  0.04711914, -0.09208461,\n       -0.13393728, -0.06016323,  0.09922572, -0.02569144, -0.04889788,\n        0.04525321,  0.06157575,  0.05718122,  0.00660924,  0.08762904,\n       -0.02774266, -0.14508928, -0.10065569, -0.02283587, -0.07883998,\n        0.05013602,  0.00815255,  0.00208391, -0.14137486,  0.07725307,\n       -0.06021554, -0.01064628,  0.12785994, -0.08564977,  0.07592773,\n       -0.08248466,  0.00200544, -0.04690988, -0.08150809, -0.04201398,\n       -0.13351004,  0.07730538,  0.01541574,  0.05201939,  0.11541312,\n        0.0753697 , -0.14425223,  0.03500366,  0.00509208,  0.01381138,\n        0.01489258, -0.0942906 ,  0.04122489,  0.13232422,  0.09607369,\n        0.06436593, -0.01356724, -0.12927246, -0.11495536, -0.11043876,\n       -0.09354074,  0.05378069,  0.00645229,  0.00233677,  0.00446429,\n        0.00651005, -0.01910727, -0.00717981,  0.06626674, -0.02758789,\n       -0.01529367,  0.01288714, -0.02968052,  0.05861119, -0.03620911,\n        0.07164656, -0.02800642,  0.12217494, -0.07842146,  0.02682931,\n        0.19688198, -0.02151925,  0.0502254 ,  0.04460907,  0.04406738,\n       -0.01579939, -0.02394322, -0.03370884,  0.08361816, -0.02552141,\n        0.00234549,  0.01980591,  0.03787667,  0.05043248,  0.20270647,\n       -0.09791783, -0.06281389,  0.02137974,  0.04821777, -0.00690569,\n       -0.07019043, -0.00513567, -0.03424944, -0.03226144,  0.1381836 ,\n        0.06613159,  0.02285222, -0.02199009,  0.04159546,  0.04765211,\n        0.12098912,  0.0088501 , -0.08383615,  0.01003374, -0.1114066 ,\n        0.02939715, -0.00156948,  0.01427351,  0.03184945, -0.02974156,\n       -0.02577427, -0.05263846, -0.06229946, -0.11816406, -0.0834089 ,\n       -0.01010568,  0.08672224,  0.10797773, -0.02626256, -0.01416016,\n       -0.00788225,  0.21868025, -0.07354736, -0.08081055, -0.08340454,\n       -0.07858712, -0.05860247,  0.04783412, -0.04728481, -0.00047084,\n       -0.03280204, -0.10741752,  0.1291155 , -0.03518568,  0.04464286,\n       -0.16380093, -0.10147095, -0.09716797, -0.02075195, -0.10020228,\n        0.0198931 ,  0.00974819,  0.06773158,  0.13999721,  0.0169329 ,\n        0.12573351,  0.00324358,  0.07121931,  0.00605556, -0.18300083,\n        0.11758859, -0.09776088,  0.09688895, -0.06263951, -0.06908308,\n        0.08535331,  0.04931641, -0.01993234,  0.07979911,  0.08759417,\n        0.02446638, -0.05088588, -0.01766532,  0.15168108, -0.04960414,\n        0.01420048,  0.14135742, -0.14833286, -0.0208653 , -0.12142944,\n        0.08032445,  0.12606375,  0.07892717, -0.08328683,  0.00617327,\n        0.01259504,  0.05493164,  0.05684989, -0.00456892,  0.07371303,\n       -0.1312403 ,  0.01862444, -0.02057757,  0.10668945, -0.06036949,\n        0.1145886 , -0.09999303,  0.01841518,  0.0663365 , -0.09120397,\n        0.01802281, -0.09905352, -0.04586356,  0.02202497, -0.01943534,\n        0.0023019 ,  0.00746373,  0.02286203, -0.15555246,  0.00526646,\n       -0.00893293,  0.01703753,  0.08877999,  0.08398438, -0.05494908,\n        0.0521371 ,  0.00645229,  0.07835388,  0.0746678 ,  0.01464844,\n       -0.05840192,  0.09678432, -0.05876813, -0.04715402, -0.07484654,\n       -0.00322614, -0.12447684, -0.01474871,  0.0412396 ,  0.08477239,\n        0.09177943,  0.1147025 , -0.01180594, -0.13505337,  0.05972181,\n        0.02730887, -0.00063215,  0.02261789,  0.01771763,  0.09901647,\n       -0.10939244, -0.13861084, -0.0249721 , -0.02666364, -0.00687081,\n        0.00377982, -0.125     ,  0.00370571,  0.02490234,  0.06330217,\n       -0.00450788, -0.18743025,  0.08141218, -0.01631382,  0.05971854,\n       -0.12163435, -0.00455911, -0.15401132,  0.01948111, -0.00366211,\n       -0.01757376,  0.02050345,  0.07419259,  0.06335449, -0.03625488],\n      dtype=float32)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = [w[\"journey\"], w[\"thousand\"], w[\"miles\"], w[\"begins\"], w[\"with\"], w[\"single\"], w[\"step\"]]\n",
    "mean_vector_2 = np.mean(vectors, axis=0)\n",
    "mean_vector_2 = mean_vector_2\n",
    "mean_vector_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.654121799164755\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "from numpy import dot\n",
    "\n",
    "value1 = float(dot(mean_vector_1, mean_vector_2))\n",
    "value2 = (norm(mean_vector_1)*norm(mean_vector_2))\n",
    "if value2 == 0:\n",
    "    print(1)\n",
    "else:\n",
    "    print(1 - value1/value2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6541217863559723"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import matutils\n",
    "\n",
    "1 - np.dot(matutils.unitvec(mean_vector_1), matutils.unitvec(mean_vector_2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU3hwN53r5un"
   },
   "source": [
    "# Two models comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-HvrEkHtFqQ"
   },
   "source": [
    "## Download one more model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z13Io-4x3Ve2"
   },
   "source": [
    "\n",
    "Let's read the google-news-vectors model and the model, trained on British national corpus http://vectors.nlpl.eu/repository/20/0.zip, using gensim. \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0QPYDnlz3X2B",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613987638974,
     "user_tz": -180,
     "elapsed": 25722,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "f8aba488-4740-4459-f564-ceec108e9995"
   },
   "source": [
    "! wget -c http://vectors.nlpl.eu/repository/20/0.zip\n",
    "! unzip 0.zip\n",
    "! head -3 model.txt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-21wScRRf1E"
   },
   "source": [
    "Let's download the model, trained on the British national corpus"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-E6OAvhw8-A7"
   },
   "source": [
    "w_british = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True)"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GpisLDDRf1T"
   },
   "source": [
    "Note, that the vector size also equals 300 in this case. Specify the part of speech of the word of interest by means of underscore . All words should be lowercased."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a7VEcvPIRf1W",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613987658417,
     "user_tz": -180,
     "elapsed": 617,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "a7c87e15-64d2-4aed-fc27-b14f0cadf1b7"
   },
   "source": [
    "try:\n",
    "    print(w_british[\"London_NOUN\"].shape)\n",
    "    print('upper is ok')\n",
    "except:\n",
    "    print(w_british[\"london_NOUN\"].shape)\n",
    "    print('lower is ok')"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "lower is ok\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5742734670639038"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_british.distance(\"professor_NOUN\", \"student_NOUN\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "'wood_NOUN'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_british.doesnt_match([\"professor_NOUN\", \"student_NOUN\", \"smart\", \"wood_NOUN\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfpohw153YQs"
   },
   "source": [
    "## The dataset for the quality evaluation\n",
    "Let's download the wordsim353 dataset. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6c2--gQ3bJF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613987682169,
     "user_tz": -180,
     "elapsed": 1499,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "4b916833-a356-496f-9ee2-42aabcbf2593"
   },
   "source": [
    "! wget -c http://alfonseca.org/pubs/ws353simrel.tar.gz \n",
    "! tar -xvf ws353simrel.tar.gz\n",
    "! head -5 wordsim353_sim_rel/wordsim_similarity_goldstandard.txt"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-16 09:44:45--  http://alfonseca.org/pubs/ws353simrel.tar.gz\r\n",
      "Resolving alfonseca.org (alfonseca.org)... 162.215.249.67\r\n",
      "Connecting to alfonseca.org (alfonseca.org)|162.215.249.67|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 5460 (5.3K) [application/x-gzip]\r\n",
      "Saving to: ‘ws353simrel.tar.gz’\r\n",
      "\r\n",
      "ws353simrel.tar.gz  100%[===================>]   5.33K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2022-03-16 09:44:46 (281 MB/s) - ‘ws353simrel.tar.gz’ saved [5460/5460]\r\n",
      "\r\n",
      "wordsim353_sim_rel/wordsim353_agreed.txt\r\n",
      "wordsim353_sim_rel/wordsim353_annotator1.txt\r\n",
      "wordsim353_sim_rel/wordsim353_annotator2.txt\r\n",
      "wordsim353_sim_rel/wordsim_relatedness_goldstandard.txt\r\n",
      "wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\r\n",
      "tiger\tcat\t7.35\r\n",
      "tiger\ttiger\t10.00\r\n",
      "plane\tcar\t5.77\r\n",
      "train\tcar\t6.31\r\n",
      "television\tradio\t6.77\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgCXUELHRf2E"
   },
   "source": [
    "## Testing dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fqy84Dmp3bYa"
   },
   "source": [
    "\n",
    "Let's extract word pairs from the file `wordsim_similarity_goldstandard.txt` and compute the vector cosine similarity in each model. Compute the correlation between the similarity estimators of the google-news-vectors model model and human ratings of the wordsim dataset, and then - the similarity correlation between the model based on British national corpus and a human ratings of the wordsim dataset. Which model is closer to the human ratings?\n",
    "\n",
    "(use only such words from wordsim dataset, which have the corresponding vectors in the British national corpus labeled as NOUNs!)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "Bpeg6FQd3clf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613987712710,
     "user_tz": -180,
     "elapsed": 588,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "d138a74d-2f65-4c6a-9978-128e1ad5051b"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\", \n",
    "                 sep=\"\\t\", header=None)\n",
    "df.columns = [\"first\", \"second\", \"score\"]\n",
    "df.head(3)"
   ],
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "   first second  score\n0  tiger    cat   7.35\n1  tiger  tiger  10.00\n2  plane    car   5.77",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first</th>\n      <th>second</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tiger</td>\n      <td>cat</td>\n      <td>7.35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tiger</td>\n      <td>tiger</td>\n      <td>10.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>plane</td>\n      <td>car</td>\n      <td>5.77</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "        first          second  score\n18   football          soccer   9.03\n19   football      basketball   6.81\n20   football          tennis   6.63\n21     Arafat         Jackson   2.50\n22    physics       chemistry   7.35\n..        ...             ...    ...\n113     image         surface   4.56\n114      life            term   4.50\n115     start           match   4.47\n116  computer            news   4.47\n117     board  recommendation   4.47\n\n[100 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first</th>\n      <th>second</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18</th>\n      <td>football</td>\n      <td>soccer</td>\n      <td>9.03</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>football</td>\n      <td>basketball</td>\n      <td>6.81</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>football</td>\n      <td>tennis</td>\n      <td>6.63</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Arafat</td>\n      <td>Jackson</td>\n      <td>2.50</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>physics</td>\n      <td>chemistry</td>\n      <td>7.35</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>113</th>\n      <td>image</td>\n      <td>surface</td>\n      <td>4.56</td>\n    </tr>\n    <tr>\n      <th>114</th>\n      <td>life</td>\n      <td>term</td>\n      <td>4.50</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>start</td>\n      <td>match</td>\n      <td>4.47</td>\n    </tr>\n    <tr>\n      <th>116</th>\n      <td>computer</td>\n      <td>news</td>\n      <td>4.47</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>board</td>\n      <td>recommendation</td>\n      <td>4.47</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[18:118]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "df = df[18:118]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDcXFGZnRf2e"
   },
   "source": [
    "## Model similarity evaluation\n",
    "We use only such words from wordsim dataset, which have the corresponding vectors in the British national corpus labeled as nouns, make 3 sets with similarity measures: \n",
    "\n",
    "1. Measures (cosine between vectors), obtained for the google-news-vectors model\n",
    "\n",
    "2. Measures (cosine between vectors), obtained for the model based on the British national corpus\n",
    "\n",
    "3. Human ratings from word_sim for the words, having the corresponding vectors in the British national corpus\n",
    "\n",
    "The skipped words from word_sim are presented in the outputs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qry_vLEd9758",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613988084025,
     "user_tz": -180,
     "elapsed": 598,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "57fb6992-77f0-47e8-efa1-6393cbd84239"
   },
   "source": [
    "gn_dist, br_dist, gn_scores, br_scores = [], [], [], []\n",
    "\n",
    "for row in df.iterrows():\n",
    "\n",
    "  w1, w2 = row[1][\"first\"], row[1][\"second\"]\n",
    "  try:\n",
    "    br_dist.append(w_british.similarity(w1.lower() + \"_NOUN\", w2.lower() + \"_NOUN\"))\n",
    "    br_scores.append(row[1][\"score\"])\n",
    "    gn_dist.append(w.similarity(w1, w2))\n",
    "    gn_scores.append(row[1][\"score\"])\n",
    "\n",
    "  except KeyError as e:\n",
    "    print(e, \"Skipping this word.\")"
   ],
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Key 'arafat_NOUN' not present\" Skipping this word.\n",
      "\"Key 'harvard_NOUN' not present\" Skipping this word.\n",
      "\"Key 'mexico_NOUN' not present\" Skipping this word.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'Arafat_NOUN' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [100]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mw_british\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mArafat_NOUN\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/NLP_OpenEdu_ITMO_Course/venv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:395\u001B[0m, in \u001B[0;36mKeyedVectors.__getitem__\u001B[0;34m(self, key_or_keys)\u001B[0m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;124;03m\"\"\"Get vector representation of `key_or_keys`.\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \n\u001B[1;32m    383\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    392\u001B[0m \n\u001B[1;32m    393\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    394\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key_or_keys, _KEY_TYPES):\n\u001B[0;32m--> 395\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey_or_keys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m vstack([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_vector(key) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m key_or_keys])\n",
      "File \u001B[0;32m~/Desktop/NLP_OpenEdu_ITMO_Course/venv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:438\u001B[0m, in \u001B[0;36mKeyedVectors.get_vector\u001B[0;34m(self, key, norm)\u001B[0m\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_vector\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    415\u001B[0m     \u001B[38;5;124;03m\"\"\"Get the key's vector, as a 1D numpy array.\u001B[39;00m\n\u001B[1;32m    416\u001B[0m \n\u001B[1;32m    417\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    436\u001B[0m \n\u001B[1;32m    437\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 438\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    439\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m norm:\n\u001B[1;32m    440\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfill_norms()\n",
      "File \u001B[0;32m~/Desktop/NLP_OpenEdu_ITMO_Course/venv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:412\u001B[0m, in \u001B[0;36mKeyedVectors.get_index\u001B[0;34m(self, key, default)\u001B[0m\n\u001B[1;32m    410\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m default\n\u001B[1;32m    411\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 412\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKey \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m not present\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Key 'Arafat_NOUN' not present\""
     ]
    }
   ],
   "source": [
    "w_british[\"Arafat_NOUN\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.012908,  0.133877,  0.119815, -0.014262, -0.145282,  0.060865,\n        0.029992,  0.029138,  0.059743, -0.039268, -0.050995,  0.008046,\n        0.010828, -0.116168,  0.0298  ,  0.024223,  0.048758,  0.006173,\n        0.028295,  0.114714, -0.003009, -0.00194 ,  0.041983,  0.018428,\n        0.035408, -0.077806, -0.017081, -0.045228, -0.008924,  0.064999,\n       -0.247234, -0.089149,  0.015466, -0.005598, -0.017188,  0.080832,\n        0.046895,  0.011464, -0.010543,  0.011781, -0.050704, -0.05064 ,\n        0.047088,  0.00158 ,  0.019804, -0.018575,  0.031504,  0.03258 ,\n       -0.045149, -0.024635,  0.106007,  0.04806 , -0.025685, -0.001249,\n       -0.120237,  0.071461,  0.030777, -0.037106, -0.00215 , -0.063987,\n        0.039495,  0.041261,  0.019401,  0.065367, -0.031992, -0.023388,\n       -0.00414 ,  0.104649, -0.058512, -0.069146, -0.010128,  0.066927,\n        0.002017, -0.029406, -0.033663, -0.043762, -0.130771, -0.069219,\n        0.016728, -0.012452,  0.081425,  0.025594,  0.053856, -0.021322,\n        0.012342, -0.028235, -0.025792, -0.063201, -0.053101, -0.01469 ,\n        0.036016,  0.040883,  0.063589,  0.029181, -0.026953, -0.008879,\n        0.080691,  0.005766, -0.033459,  0.001849,  0.011748, -0.090603,\n       -0.03711 , -0.015901,  0.034953,  0.002795,  0.048815,  0.001617,\n       -0.022197, -0.135944, -0.033174,  0.011836, -0.104239,  0.072871,\n        0.032362,  0.03034 ,  0.053988, -0.025534,  0.052642,  0.042879,\n        0.085002,  0.023823, -0.010132,  0.013503, -0.015011,  0.04731 ,\n       -0.016576, -0.04563 ,  0.031359,  0.012137, -0.025999, -0.016356,\n       -0.000309,  0.016713,  0.060606,  0.028655, -0.068083, -0.081936,\n       -0.084327,  0.059611,  0.03536 ,  0.008266, -0.035027,  0.008968,\n        0.076377, -0.012806,  0.001858, -0.085377, -0.114927,  0.010831,\n        0.070026,  0.0502  ,  0.03558 ,  0.009484, -0.016544,  0.073896,\n       -0.03362 , -0.038096,  0.088522,  0.025898, -0.035823, -0.036848,\n       -0.030396,  0.019423,  0.041965, -0.034888,  0.018435, -0.026575,\n       -0.057282, -0.082515, -0.008594,  0.01792 , -0.098962, -0.02299 ,\n       -0.023669,  0.048973, -0.126473, -0.097805,  0.00399 ,  0.022679,\n        0.090796,  0.046876, -0.007832,  0.048363,  0.031603,  0.007387,\n       -0.115651,  0.061436, -0.01444 ,  0.113592, -0.052374, -0.000379,\n       -0.164164,  0.001585, -0.107069, -0.010474,  0.046101,  0.032103,\n       -0.183677,  0.054714,  0.092658,  0.074902,  0.031942,  0.055151,\n        0.047956,  0.018289, -0.047721, -0.059881, -0.008124, -0.056389,\n        0.077994, -0.06132 , -0.021687, -0.029236, -0.062924, -0.002496,\n       -0.060699, -0.052124, -0.028833,  0.065819, -0.120979,  0.049713,\n       -0.031075,  0.029616, -0.013061, -0.004841, -0.054713, -0.043553,\n       -0.036361,  0.001817,  0.021149, -0.065371, -0.15142 , -0.082191,\n       -0.039625,  0.038452,  0.058799,  0.059483,  0.005677,  0.012348,\n       -0.015585,  0.04797 ,  0.103222, -0.01645 , -0.028002, -0.053594,\n       -0.02784 ,  0.010354,  0.004754, -0.005861, -0.035296, -0.067092,\n       -0.052713, -0.007448,  0.07915 , -0.063047, -0.003858,  0.048321,\n       -0.127557, -0.01832 ,  0.02058 , -0.033699,  0.011902,  0.050465,\n        0.039671,  0.05155 ,  0.062256, -0.131658,  0.060654,  0.125411,\n       -0.09436 , -0.011953, -0.012069, -0.02828 ,  0.107451,  0.049056,\n       -0.104435, -0.011568, -0.04818 ,  0.052343,  0.025856,  0.046596,\n       -0.0306  ,  0.01049 , -0.164973, -0.033579, -0.028775,  0.002512,\n       -0.009197, -0.033587,  0.002241, -0.020989,  0.055332,  0.010605,\n       -0.068636, -0.019466, -0.047542,  0.006839,  0.004625,  0.042322],\n      dtype=float32)"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_british[\"japanese_NOUN\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPyeIR2QtSec"
   },
   "source": [
    "## Model selection: correlation with human ratings\n",
    "\n",
    "Compute Spearman's correlation between each model and human ratings from word_sim.\n",
    "\n",
    "The results are in the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "97"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gn_dist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "97"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(br_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.73135483,\n 0.66824675,\n 0.5051179,\n 0.4371983,\n 0.59717494,\n 0.6881493,\n 0.50702006,\n 0.5838368,\n 0.6210811,\n 0.68308526,\n 0.5886159,\n 0.5083667,\n 0.2525393,\n 0.48634958,\n 0.5527407,\n 0.60839105,\n 0.3740926,\n 0.36290243,\n 0.30286193,\n 0.11830647,\n 0.3135657,\n 0.16010122,\n 0.5528684,\n 0.42671448,\n 0.42893752,\n 0.49644744,\n 0.5096533,\n 0.06294279,\n 0.3297567,\n 0.5556288,\n 0.48088345,\n 0.2597164,\n 0.19317105,\n 0.5024792,\n 0.32067436,\n 0.37273747,\n 0.28377137,\n 0.19486345,\n 0.03369916,\n 0.10605283,\n 0.034792215,\n 0.40548652,\n 0.13319406,\n 0.7258478,\n 0.33974788,\n 0.4124885,\n 0.33483714,\n 0.4673331,\n 0.16101654,\n 0.14553328,\n 0.36187765,\n 0.12772588,\n 0.6666412,\n 0.1775303,\n 0.38327035,\n 0.26695922,\n 0.2862988,\n 0.27859154,\n 0.60769564,\n 0.34199455,\n 0.5745356,\n 0.25621173,\n 0.13774039,\n 0.3653528,\n 0.4636158,\n 0.5295588,\n 0.654408,\n 0.30510467,\n 0.3194861,\n 0.6655317,\n 0.76640123,\n 0.15232418,\n 0.60576504,\n 0.17167465,\n 0.37073973,\n 0.63757634,\n 0.45277104,\n 0.33256373,\n 0.34269473,\n 0.30354035,\n 0.09379565,\n 0.1629582,\n 0.15370694,\n 0.14423443,\n 0.08025178,\n 0.18474203,\n 0.09658686,\n 0.119007275,\n 0.24616712,\n 0.18779546,\n 0.066302165,\n 0.23487988,\n 0.12843585,\n 0.22676063,\n 0.24805228,\n 0.103998095,\n 0.32118106]"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gn_dist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "[9.03,\n 6.81,\n 6.63,\n 7.35,\n 8.46,\n 8.13,\n 6.87,\n 8.94,\n 8.96,\n 9.29,\n 8.83,\n 9.1,\n 8.87,\n 9.02,\n 9.29,\n 8.79,\n 7.52,\n 7.1,\n 7.38,\n 4.42,\n 8.42,\n 9.04,\n 8.0,\n 8.0,\n 7.08,\n 6.85,\n 7.0,\n 4.77,\n 5.62,\n 8.08,\n 6.71,\n 5.58,\n 8.45,\n 8.08,\n 8.02,\n 5.85,\n 6.04,\n 6.85,\n 2.92,\n 3.69,\n 2.15,\n 7.42,\n 7.27,\n 8.66,\n 6.22,\n 6.5,\n 7.59,\n 7.56,\n 5.0,\n 4.63,\n 7.88,\n 5.0,\n 8.97,\n 6.44,\n 8.88,\n 6.88,\n 7.81,\n 7.63,\n 8.44,\n 7.63,\n 7.78,\n 9.22,\n 7.13,\n 7.89,\n 7.47,\n 8.34,\n 8.7,\n 7.81,\n 5.7,\n 8.36,\n 8.3,\n 5.25,\n 8.53,\n 6.88,\n 5.56,\n 7.83,\n 7.59,\n 7.19,\n 6.31,\n 5.0,\n 5.0,\n 4.97,\n 4.94,\n 4.94,\n 4.88,\n 4.81,\n 4.75,\n 4.75,\n 4.75,\n 4.69,\n 4.62,\n 4.59,\n 4.56,\n 4.5,\n 4.47,\n 4.47,\n 4.47]"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gn_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZlbnwcq-SCL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1613988090311,
     "user_tz": -180,
     "elapsed": 606,
     "user": {
      "displayName": "Дмитрий Волчек",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgN8jjHr8b6AlqmkI_BBSJH_qXpcmh3mgxKpBXd=s64",
      "userId": "12396512946067001179"
     }
    },
    "outputId": "b42bc32c-b698-4c0f-b5e4-fc0d64370a94"
   },
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "#enter your code here\n",
    "coef, p = spearmanr(gn_dist, gn_scores)\n",
    "print(\"gn_dist  Spearman R: %.4f\" % coef)\n",
    "\n",
    "coef, p = spearmanr(br_dist, br_scores)\n",
    "print(\"br_dist  Spearman R: %.4f\" % coef)"
   ],
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gn_dist  Spearman R: 0.7186\n",
      "br_dist  Spearman R: 0.6761\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtlAncsQANfx"
   },
   "source": [
    "You can notice, that the google-news-vectors model is slighly better in this case."
   ]
  }
 ]
}