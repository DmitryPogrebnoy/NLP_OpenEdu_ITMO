{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "3_Students_1_en.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAyzWDzFdnLa"
      },
      "source": [
        "## Text classification: Spam or Ham"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh91cKPmdnLb"
      },
      "source": [
        "In this example based on the classical dataset Spambase Dataset (https://archive.ics.uci.edu/ml/datasets/spambase) we will try to make our own spam filter using scikit-learn library. The dataset contains text corpora of  5.574 text messages with labels \"spam\" or \"ham\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4Bf-AmgdnLb"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWvXDXKrdnLb"
      },
      "source": [
        "Data are attached to the task description for your convinience"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnJwvQzbdnLb"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data.csv', encoding='latin-1')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRqzedIIdnLc"
      },
      "source": [
        "We delete all other columns except for two of interest: text messages and labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO59-HEadnLc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2d14015f-89eb-48a9-b726-65078de910a6"
      },
      "source": [
        "df = df[['v1', 'v2']]\n",
        "df = df.rename(columns = {'v1': 'label', 'v2': 'text'})\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                               text\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e193e4c9-a1ec-410d-9322-768ecde9612d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e193e4c9-a1ec-410d-9322-768ecde9612d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e193e4c9-a1ec-410d-9322-768ecde9612d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e193e4c9-a1ec-410d-9322-768ecde9612d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU2xwmvIdnLd"
      },
      "source": [
        "Delete duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iveCG_bXdnLd"
      },
      "source": [
        "df = df.drop_duplicates('text')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuPip3mzdnLd"
      },
      "source": [
        "Change labels to binary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsKdfy6-dnLd"
      },
      "source": [
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vQJK8LNdnLe"
      },
      "source": [
        "### Text pre-processing (Task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8tefVdTdnLe"
      },
      "source": [
        "We need to complete the function for text pre-processing, to pre-process the text the following way:\n",
        "* convert text to lowercase;\n",
        "* remove stop-words;\n",
        "* remove punctuation marks;\n",
        "* normalizes the text using Snowball stemmer.\n",
        "\n",
        "We recommend to use the NLTK library, in order not to compile a list of stop-words and not to implement the stemming algorithm yourself. Click the link to find the examples of stemmers application (https://www.nltk.org/howto/stem.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhU1BvAHdnLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9472ba-77f2-4edb-c699-0cabf0155d8c"
      },
      "source": [
        "from nltk import stem\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stemmer = stem.SnowballStemmer('english')\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # your code here\n",
        "    return text"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM-Lrt6ddnLe"
      },
      "source": [
        "Check that the function works correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSuPqUb2dnLe"
      },
      "source": [
        "assert preprocess(\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\") == \"im gonna home soon dont want talk stuff anymor tonight k ive cri enough today\"\n",
        "assert preprocess(\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\") == \"go jurong point crazi avail bugi n great world la e buffet cine got amor wat\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84H8mOmpdnLe"
      },
      "source": [
        "Apply to the text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtM4626ednLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e323dd-25de-4d22-9dc0-5e9b7118a1d5"
      },
      "source": [
        "df['text'] = df['text'].apply(preprocess)\n",
        "df['text']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       go jurong point crazi avail bugi n great world...\n",
              "1                                   ok lar joke wif u oni\n",
              "2       free entri 2 wkli comp win fa cup final tkts 2...\n",
              "3                     u dun say earli hor u c alreadi say\n",
              "4               nah dont think goe usf live around though\n",
              "                              ...                        \n",
              "5567    2nd time tri 2 contact u u å750 pound prize 2 ...\n",
              "5568                             ì_ b go esplanad fr home\n",
              "5569                              piti mood soani suggest\n",
              "5570    guy bitch act like id interest buy someth els ...\n",
              "5571                                       rofl true name\n",
              "Name: text, Length: 5169, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRyqtqUtdnLe"
      },
      "source": [
        "### Split the data to the training and test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt7Z5NCMdnLe"
      },
      "source": [
        "y = df['label'].values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r4PJBctdnLe"
      },
      "source": [
        "Now we need to split the data to test (test) and training (train) sets. Scikit-learn library contains ready to use tools to do it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1c9ARWIdnLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c80038-517d-42d9-d3f7-cfcd76d41c4e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.3, random_state=51)\n",
        "X_test"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "634     dear voucher holder 2 claim week offer pc go h...\n",
              "1149                                            drop tank\n",
              "2375    thanx 4 2day u r goodmat think ur rite sari as...\n",
              "845     meanwhil shit suit xavier decid give us ltgt s...\n",
              "155                                      aaooooright work\n",
              "                              ...                        \n",
              "1977    repli win å100 week 2006 fifa world cup held s...\n",
              "481              yo carlo friend alreadi ask work weekend\n",
              "1632    hello littl parti anim thought id buzz friend ...\n",
              "5280                           vikki come around lttimegt\n",
              "3566    collect valentin weekend pari inc flight hotel...\n",
              "Name: text, Length: 1551, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOV7Ub4ldnLe"
      },
      "source": [
        "### Classifier training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enAzNefqdnLe"
      },
      "source": [
        "We came to the classifier training now.\n",
        "\n",
        "First we extract features from the texts. It is strongly recommened to try several methods in order to check how each method influences the result (more information on defferent text representation methods you can find on the link https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction).\n",
        "\n",
        "Then we train the classifier. We use SVM, but you can try different algorithms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtfcmJ7NdnLe"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "# exctract features from the texts\n",
        "vectorizer = TfidfVectorizer(decode_error='ignore')\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIQQo8j3dnLe"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#train SVM model\n",
        "\n",
        "model = LinearSVC(random_state = 51, C = 1)\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn9kvQaZdnLe"
      },
      "source": [
        "Selfcheck. If the function ```preprocess``` is complimented correctly, then you should get the following model evaluation results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGxDEYnjdnLe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb775bb7-dbc7-4126-edb0-fccb8a689e77"
      },
      "source": [
        "print(classification_report(y_test, predictions, digits=3))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.984     0.993     0.988      1355\n",
            "           1      0.946     0.888     0.916       196\n",
            "\n",
            "    accuracy                          0.979      1551\n",
            "   macro avg      0.965     0.940     0.952      1551\n",
            "weighted avg      0.979     0.979     0.979      1551\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nffLu6UdnLf"
      },
      "source": [
        "Let's predict results for the specified text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prWswDzudnLf"
      },
      "source": [
        "txt = \"As a valued customer, I am pleased to advise you that following recent review of your Mob No. you are awarded with a å£1500 Bonus Prize, call 09066364589\"\n",
        "txt = preprocess(txt)\n",
        "txt = vectorizer.transform([txt])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brfpnzR7dnLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9a82d0-7787-4f95-abed-49e742700b42"
      },
      "source": [
        "model.predict(txt)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The message is classified as spam."
      ],
      "metadata": {
        "id": "-gQ4z-NbIkQO"
      }
    }
  ]
}